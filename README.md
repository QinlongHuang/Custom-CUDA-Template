# Code Template for Custom CUDA operations
Several simple examples for PyTorch calling custom CUDA operators.

Compile the CUDA kernels and their cpp wrappers using JIT(Just-In-Time).

For more accurate time statistics, you'd best use `nvprof` or `nsys` to run the code.

## Environments
- OS: Ubuntu 20.04
- GPU: NVIDIA RTX 4090 w/ Driver 525.147.05
- CUDA: 11.8
- Python: 3.8.18
- PyTorch: 2.1.2+cu118
- CMake: 3.26.0-rc6
- Ninja: 1.10.0
- GCC: 9.4.0

Cannot ensure successful running in other environments.

## Code structure
```
ðŸ“¦Custom-CUDA-Template
 â”£ ðŸ“‚src
 â”ƒ â”— ðŸ“‚cuda_ops
 â”ƒ â”ƒ â”£ ðŸ“‚include
 â”ƒ â”ƒ â”ƒ â”— ðŸ“œadd_op.h
 â”ƒ â”ƒ â”£ ðŸ“‚kernels
 â”ƒ â”ƒ â”ƒ â”£ ðŸ“œadd_kernel.cu
 â”ƒ â”ƒ â”ƒ â”— ðŸ“œfused_leaky_relu_kernel.cu
 â”ƒ â”ƒ â”£ ðŸ“œ__init__.py
 â”ƒ â”ƒ â”£ ðŸ“œadd.py
 â”ƒ â”ƒ â”£ ðŸ“œadd_op.cpp
 â”ƒ â”ƒ â”£ ðŸ“œfused_leaky_relu.py
 â”ƒ â”ƒ â”— ðŸ“œfused_leaky_relu_op.cpp
 â”£ ðŸ“œ.project-root
 â”— ðŸ“œREADME.md
```

## Reference
- [godweiyang/NN-CUDA-Example](https://github.com/godweiyang/NN-CUDA-Example)
- [rosinality/stylegan2-pytorch](https://github.com/rosinality/stylegan2-pytorch)